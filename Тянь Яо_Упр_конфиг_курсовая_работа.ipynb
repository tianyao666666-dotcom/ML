{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=N7LJUE5KY47X5YIOQ0P62YWNM6LMMZ\n",
    "%env CLEARML_API_SECRET_KEY=if0s4bvxfz8Vrlx9vXgd0_INSvzWlQCFcZfJb_N96WcUjbHb3xIOMYjHCWh2zipx6-g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cfe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "os.environ[\"CLEARML_WEB_HOST\"] = \"https://app.clear.ml\"\n",
    "os.environ[\"CLEARML_API_HOST\"] = \"https://api.clear.ml\"\n",
    "os.environ[\"CLEARML_FILES_HOST\"] = \"https://files.clear.ml\"\n",
    "os.environ[\"CLEARML_API_ACCESS_KEY\"] = \"N7LJUE5KY47X5YIOQ0P62YWNM6LMMZ\"\n",
    "os.environ[\"CLEARML_API_SECRET_KEY\"] = \"if0s4bvxfz8Vrlx9vXgd0_INSvzWlQCFcZfJb_N96WcUjbHb3xIOMYjHCWh2zipx6-g\"\n",
    "\n",
    "from clearml import Task\n",
    "\n",
    "try:\n",
    "    task = Task.init(project_name=\"Test\", task_name=\"Test\")\n",
    "    print(\"è¿æ¥æˆåŠŸï¼Œä»»åŠ¡ID:\", task.id)\n",
    "    task.close()\n",
    "except Exception as e:\n",
    "    print(\"è¿æ¥å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17134ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ•°æ®é¢„å¤„ç†ä»»åŠ¡ - åŸºäºä½ çš„adult_model_clear_ml.ipynbä»£ç \n",
    "åˆ›å»ºç‹¬ç«‹çš„ClearML Taskå’ŒDatasetç‰ˆæœ¬\n",
    "\"\"\"\n",
    "\n",
    "# ==================== 1. å¯¼å…¥åº“ ====================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# ==================== 2. è®¾ç½®ClearMLå‡­è¯ ====================\n",
    "# ä½¿ç”¨ä½ å·²æœ‰çš„é…ç½®æ–¹å¼\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=N7LJUE5KY47X5YIOQ0P62YWNM6LMMZ\n",
    "%env CLEARML_API_SECRET_KEY=if0s4bvxfz8Vrlx9vXgd0_INSvzWlQCFcZfJb_N96WcUjbHb3xIOMYjHCWh2zipx6-g\n",
    "\n",
    "# ==================== 3. åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†Task ====================\n",
    "from clearml import Task, Dataset\n",
    "\n",
    "# åˆ›å»ºç‹¬ç«‹çš„æ•°æ®é¢„å¤„ç†ä»»åŠ¡\n",
    "print(\"åˆå§‹åŒ–ç‹¬ç«‹çš„æ•°æ®é¢„å¤„ç†ä»»åŠ¡...\")\n",
    "task_data_prep = Task.init(\n",
    "    project_name='Adult Income - ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ',  # é¡¹ç›®åç§°\n",
    "    task_name='Data Preprocessing - Task 1',  # ä»»åŠ¡åç§°\n",
    "    task_type=Task.TaskTypes.data_processing,  # æ˜ç¡®æŒ‡å®šä¸ºæ•°æ®å¤„ç†ä»»åŠ¡\n",
    "    tags=['data-processing', 'preprocessing', 'ĞºÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ']\n",
    ")\n",
    "\n",
    "print(f\"âœ… æ•°æ®é¢„å¤„ç†ä»»åŠ¡åˆ›å»ºæˆåŠŸ!\")\n",
    "print(f\"ğŸ“‹ Task ID: {task_data_prep.id}\")\n",
    "\n",
    "# ==================== 4. åŠ è½½åŸå§‹æ•°æ® ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤1: åŠ è½½åŸå§‹æ•°æ®\")\n",
    "\n",
    "fpath = 'adults.csv'\n",
    "df_raw = pd.read_csv(fpath)\n",
    "\n",
    "print(f\"âœ… æ•°æ®åŠ è½½æˆåŠŸ!\")\n",
    "print(f\"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: {df_raw.shape}\")\n",
    "print(f\"ğŸ“‹ å‰3è¡Œæ•°æ®é¢„è§ˆ:\")\n",
    "print(df_raw.head(3))\n",
    "\n",
    "# ==================== 5. ä¸Šä¼ åŸå§‹æ•°æ®ä½œä¸ºArtifact ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤2: ä¸Šä¼ åŸå§‹æ•°æ®åˆ°ClearML\")\n",
    "\n",
    "task_data_prep.upload_artifact(\n",
    "    name='raw_data.csv',\n",
    "    artifact_object=fpath,\n",
    "    metadata={\n",
    "        'description': 'åŸå§‹Adult Incomeæ•°æ®é›†',\n",
    "        'rows': df_raw.shape[0],\n",
    "        'columns': df_raw.shape[1]\n",
    "    }\n",
    ")\n",
    "print(\"âœ… åŸå§‹æ•°æ®å·²ä¸Šä¼ ä¸ºArtifact\")\n",
    "\n",
    "# ==================== 6. æ•°æ®é¢„å¤„ç†ï¼ˆåŸºäºä½ çš„ä»£ç ï¼‰ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤3: æ•°æ®é¢„å¤„ç†\")\n",
    "\n",
    "# è®°å½•é¢„å¤„ç†æ­¥éª¤\n",
    "preprocessing_steps = []\n",
    "\n",
    "# 6.1 åˆ é™¤ä¸ç›¸å…³ç‰¹å¾ï¼ˆåŸºäºä½ çš„ä»£ç ï¼‰\n",
    "print(\"\\n1. åˆ é™¤ä¸ç›¸å…³ç‰¹å¾...\")\n",
    "df = df_raw.drop(['fnlwgt', 'education_num'], axis=1)\n",
    "print(f\"âœ… å·²åˆ é™¤ 'fnlwgt' å’Œ 'education_num' åˆ—\")\n",
    "preprocessing_steps.append(\"åˆ é™¤ fnlwgt å’Œ education_num åˆ—\")\n",
    "\n",
    "# 6.2 å¤„ç†ç¼ºå¤±å€¼ï¼ˆåŸºäºä½ çš„ä»£ç ï¼‰\n",
    "print(\"\\n2. å¤„ç†ç¼ºå¤±å€¼...\")\n",
    "col_names = df.columns\n",
    "for c in col_names:\n",
    "    df = df.replace(\"?\", np.nan)\n",
    "    \n",
    "# ç”¨ä¼—æ•°å¡«å……ç¼ºå¤±å€¼\n",
    "df = df.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "print(\"âœ… å·²å¤„ç†ç¼ºå¤±å€¼ï¼ˆ'?'æ›¿æ¢å¹¶ç”¨ä¼—æ•°å¡«å……ï¼‰\")\n",
    "preprocessing_steps.append(\"å¤„ç†ç¼ºå¤±å€¼\")\n",
    "\n",
    "# 6.3 ç®€åŒ–åˆ†ç±»å˜é‡ï¼ˆåŸºäºä½ çš„ä»£ç ï¼‰\n",
    "print(\"\\n3. ç®€åŒ–åˆ†ç±»å˜é‡...\")\n",
    "df.replace(['Divorced', 'Married-AF-spouse',\n",
    "            'Married-civ-spouse', 'Married-spouse-absent',\n",
    "            'Never-married', 'Separated', 'Widowed'],\n",
    "           ['divorced', 'married', 'married', 'married',\n",
    "            'not married', 'not married', 'not married'], inplace=True)\n",
    "print(\"âœ… å·²ç®€åŒ–å©šå§»çŠ¶æ€å˜é‡\")\n",
    "preprocessing_steps.append(\"ç®€åŒ–å©šå§»çŠ¶æ€å˜é‡\")\n",
    "\n",
    "# 6.4 ç¼–ç åˆ†ç±»å˜é‡ï¼ˆåŸºäºä½ çš„ä»£ç ï¼‰\n",
    "print(\"\\n4. ç¼–ç åˆ†ç±»å˜é‡...\")\n",
    "category_col = ['workclass', 'race', 'education', 'marital_status', 'occupation',\n",
    "                'relationship', 'sex', 'native_country', 'class']\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "mapping_dict = {}\n",
    "for col in category_col:\n",
    "    df[col] = labelEncoder.fit_transform(df[col])\n",
    "    \n",
    "    le_name_mapping = dict(zip(labelEncoder.classes_,\n",
    "                               labelEncoder.transform(labelEncoder.classes_)))\n",
    "    mapping_dict[col] = le_name_mapping\n",
    "\n",
    "print(f\"âœ… å·²ç¼–ç  {len(category_col)} ä¸ªåˆ†ç±»å˜é‡\")\n",
    "preprocessing_steps.append(\"ç¼–ç åˆ†ç±»å˜é‡\")\n",
    "\n",
    "# 6.5 ä¿å­˜ç¼–ç æ˜ å°„\n",
    "print(\"\\n5. ä¿å­˜ç¼–ç æ˜ å°„...\")\n",
    "encoding_map_file = 'encoding_mappings.json'\n",
    "\n",
    "# è‡ªå®šä¹‰åºåˆ—åŒ–å™¨ï¼Œå°†NumPyç±»å‹è½¬æ¢ä¸ºPythonå†…ç½®ç±»å‹\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.floating)):\n",
    "            return obj.item()  # è½¬æ¢ä¸ºPythonå†…ç½®ç±»å‹\n",
    "        return super().default(obj)\n",
    "\n",
    "with open(encoding_map_file, 'w') as f:\n",
    "    json.dump(mapping_dict, f, indent=2, cls=NumpyEncoder)\n",
    "# ==================== 7. æ•°æ®åˆ†å‰²ï¼ˆåŸºäºä½ çš„ä»£ç ï¼‰ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤4: æ•°æ®åˆ†å‰²\")\n",
    "\n",
    "# å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡\n",
    "X = df.values[:, 0:12]\n",
    "Y = df.values[:, 12]\n",
    "\n",
    "# åˆ†å‰²æ•°æ®ï¼ˆä½¿ç”¨ä½ çš„å‚æ•°ï¼‰\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=100\n",
    ")\n",
    "\n",
    "print(f\"âœ… æ•°æ®åˆ†å‰²å®Œæˆ:\")\n",
    "print(f\"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾\")\n",
    "print(f\"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬, {X_test.shape[1]} ç‰¹å¾\")\n",
    "\n",
    "# è®¡ç®—ç±»åˆ«åˆ†å¸ƒ\n",
    "train_class_0 = (y_train == 0).sum()\n",
    "train_class_1 = (y_train == 1).sum()\n",
    "train_total = len(y_train)\n",
    "\n",
    "print(f\"   è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ:\")\n",
    "print(f\"     ç±»åˆ«0 (<=50K): {train_class_0} ({(train_class_0/train_total)*100:.1f}%)\")\n",
    "print(f\"     ç±»åˆ«1 (>50K): {train_class_1} ({(train_class_1/train_total)*100:.1f}%)\")\n",
    "\n",
    "# ==================== 8. ä¿å­˜å¤„ç†åçš„æ•°æ® ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤5: ä¿å­˜å¤„ç†åçš„æ•°æ®\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# ä¿å­˜å¤„ç†åçš„å®Œæ•´æ•°æ®é›†\n",
    "processed_df_file = 'adult_processed_full.pkl'\n",
    "with open(processed_df_file, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "# ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "train_data_file = 'adult_train_data.pkl'\n",
    "test_data_file = 'adult_test_data.pkl'\n",
    "\n",
    "train_data = {'X': X_train, 'y': y_train}\n",
    "test_data = {'X': X_test, 'y': y_test}\n",
    "\n",
    "with open(train_data_file, 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "with open(test_data_file, 'wb') as f:\n",
    "    pickle.dump(test_data, f)\n",
    "\n",
    "print(\"âœ… å¤„ç†åçš„æ•°æ®å·²ä¿å­˜ä¸º pickle æ–‡ä»¶\")\n",
    "\n",
    "# ==================== 9. ä¸Šä¼ å¤„ç†åçš„æ•°æ®ä½œä¸ºArtifact ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤6: ä¸Šä¼ å¤„ç†åçš„æ•°æ®åˆ°ClearML\")\n",
    "\n",
    "# ä¸Šä¼ å¤„ç†åçš„å®Œæ•´æ•°æ®é›†\n",
    "task_data_prep.upload_artifact(\n",
    "    name='processed_data_full.pkl',\n",
    "    artifact_object=processed_df_file\n",
    ")\n",
    "\n",
    "# ä¸Šä¼ è®­ç»ƒé›†\n",
    "task_data_prep.upload_artifact(\n",
    "    name='train_data.pkl',\n",
    "    artifact_object=train_data_file\n",
    ")\n",
    "\n",
    "# ä¸Šä¼ æµ‹è¯•é›†\n",
    "task_data_prep.upload_artifact(\n",
    "    name='test_data.pkl',\n",
    "    artifact_object=test_data_file\n",
    ")\n",
    "\n",
    "# ä¸Šä¼ ç¼–ç æ˜ å°„\n",
    "task_data_prep.upload_artifact(\n",
    "    name='encoding_mappings.json',\n",
    "    artifact_object=encoding_map_file\n",
    ")\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰å¤„ç†åçš„æ•°æ®å·²ä¸Šä¼ ä¸ºArtifact\")\n",
    "\n",
    "# ==================== 10. åˆ›å»ºDatasetç‰ˆæœ¬ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤7: åˆ›å»ºClearML Datasetç‰ˆæœ¬\")\n",
    "\n",
    "# Datasetç‰ˆæœ¬1.0ï¼šå®Œæ•´å¤„ç†åçš„æ•°æ®\n",
    "print(\"åˆ›å»º Dataset v1.0 (å®Œæ•´å¤„ç†åçš„æ•°æ®)...\")\n",
    "dataset_v1 = Dataset.create(\n",
    "    dataset_name='adult_income_processed',\n",
    "    dataset_project='Adult Income - ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ',\n",
    "    dataset_version='1.0',\n",
    "    description='Adult Incomeæ•°æ®é›†å®Œæ•´é¢„å¤„ç†åçš„ç‰ˆæœ¬ï¼ŒåŒ…å«æ¸…æ´—å’Œç¼–ç '\n",
    ")\n",
    "\n",
    "# æ·»åŠ æ–‡ä»¶åˆ°Dataset\n",
    "dataset_v1.add_files(processed_df_file)\n",
    "dataset_v1.add_files(encoding_map_file)\n",
    "\n",
    "# ä¸Šä¼ å¹¶å®ŒæˆDataset\n",
    "dataset_v1.upload()\n",
    "dataset_v1.finalize()\n",
    "\n",
    "print(f\"âœ… Dataset v1.0 åˆ›å»ºæˆåŠŸ!\")\n",
    "print(f\"   Dataset ID: {dataset_v1.id}\")\n",
    "\n",
    "# Datasetç‰ˆæœ¬2.0ï¼šè®­ç»ƒ/æµ‹è¯•åˆ†å‰²\n",
    "print(\"\\nåˆ›å»º Dataset v2.0 (è®­ç»ƒ/æµ‹è¯•åˆ†å‰²)...\")\n",
    "dataset_v2 = Dataset.create(\n",
    "    dataset_name='adult_income_splits',\n",
    "    dataset_project='Adult Income - ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ',\n",
    "    dataset_version='2.0',\n",
    "    parent_datasets=[dataset_v1.id],  # æŒ‡å®šçˆ¶ç‰ˆæœ¬\n",
    "    description='åŸºäºv1.0åˆ†å‰²çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†'\n",
    ")\n",
    "\n",
    "# æ·»åŠ æ–‡ä»¶åˆ°Dataset\n",
    "dataset_v2.add_files(train_data_file)\n",
    "dataset_v2.add_files(test_data_file)\n",
    "dataset_v2.add_files(encoding_map_file)\n",
    "\n",
    "# ä¸Šä¼ å¹¶å®ŒæˆDataset\n",
    "dataset_v2.upload()\n",
    "dataset_v2.finalize()\n",
    "\n",
    "print(f\"âœ… Dataset v2.0 åˆ›å»ºæˆåŠŸ!\")\n",
    "print(f\"   Dataset ID: {dataset_v2.id}\")\n",
    "\n",
    "# ==================== 11. è®°å½•é…ç½®å’Œç»“æœ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤8: è®°å½•é…ç½®å’Œç»“æœ\")\n",
    "\n",
    "# åˆ›å»ºé…ç½®å­—å…¸\n",
    "config = {\n",
    "    'preprocessing': {\n",
    "        'steps': preprocessing_steps,\n",
    "        'dropped_columns': ['fnlwgt', 'education_num'],\n",
    "        'test_size': 0.3,\n",
    "        'random_state': 100,\n",
    "        'encoded_columns': category_col\n",
    "    },\n",
    "    'data_statistics': {\n",
    "        'original_shape': df_raw.shape,\n",
    "        'processed_shape': df.shape,\n",
    "        'train_samples': X_train.shape[0],\n",
    "        'test_samples': X_test.shape[0],\n",
    "        'features': X_train.shape[1],\n",
    "        'class_distribution_train': {\n",
    "            'class_0': int(train_class_0),\n",
    "            'class_1': int(train_class_1),\n",
    "            'class_0_percent': float((train_class_0/train_total)*100),\n",
    "            'class_1_percent': float((train_class_1/train_total)*100)\n",
    "        }\n",
    "    },\n",
    "    'datasets': {\n",
    "        'v1.0': dataset_v1.id,\n",
    "        'v2.0': dataset_v2.id\n",
    "    }\n",
    "}\n",
    "\n",
    "# è¿æ¥åˆ°Taské…ç½®\n",
    "task_data_prep.connect(config)\n",
    "print(\"âœ… é…ç½®å·²è®°å½•åˆ°ClearML\")\n",
    "\n",
    "# ==================== 12. ç”ŸæˆæŠ¥å‘Š ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤9: ç”ŸæˆæŠ¥å‘Š\")\n",
    "\n",
    "# è·å–logger\n",
    "logger = task_data_prep.get_logger()\n",
    "\n",
    "# æŠ¥å‘Šæ•°æ®ç»Ÿè®¡\n",
    "logger.report_table(\n",
    "    title=\"æ•°æ®é¢„å¤„ç†ç»Ÿè®¡\",\n",
    "    series=\"summary\",\n",
    "    table_plot=[\n",
    "        [\"æŒ‡æ ‡\", \"åŸå§‹æ•°æ®\", \"å¤„ç†åæ•°æ®\"],\n",
    "        [\"æ ·æœ¬æ•°\", df_raw.shape[0], df.shape[0]],\n",
    "        [\"ç‰¹å¾æ•°\", df_raw.shape[1], df.shape[1]],\n",
    "        [\"è®­ç»ƒé›†æ ·æœ¬\", \"-\", X_train.shape[0]],\n",
    "        [\"æµ‹è¯•é›†æ ·æœ¬\", \"-\", X_test.shape[0]]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# æŠ¥å‘Šç±»åˆ«åˆ†å¸ƒ\n",
    "logger.report_table(\n",
    "    title=\"è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ\",\n",
    "    series=\"class_distribution\",\n",
    "    table_plot=[\n",
    "        [\"ç±»åˆ«\", \"æ•°é‡\", \"ç™¾åˆ†æ¯”\"],\n",
    "        [\"<=50K\", int(train_class_0), f\"{(train_class_0/train_total)*100:.1f}%\"],\n",
    "        [\">50K\", int(train_class_1), f\"{(train_class_1/train_total)*100:.1f}%\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# æŠ¥å‘Šé¢„å¤„ç†æ­¥éª¤\n",
    "steps_table = [[\"æ­¥éª¤\", \"æè¿°\"]]\n",
    "for i, step in enumerate(preprocessing_steps, 1):\n",
    "    steps_table.append([f\"æ­¥éª¤ {i}\", step])\n",
    "\n",
    "logger.report_table(\n",
    "    title=\"é¢„å¤„ç†æ­¥éª¤\",\n",
    "    series=\"steps\",\n",
    "    table_plot=steps_table\n",
    ")\n",
    "\n",
    "print(\"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ\")\n",
    "\n",
    "# ==================== 13. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤10: æ¸…ç†ä¸´æ—¶æ–‡ä»¶\")\n",
    "\n",
    "import os\n",
    "temp_files = [processed_df_file, train_data_file, test_data_file, encoding_map_file]\n",
    "for file in temp_files:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"ğŸ—‘ï¸  å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file}\")\n",
    "\n",
    "# ==================== 14. å®Œæˆä»»åŠ¡ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ æ•°æ®é¢„å¤„ç†ä»»åŠ¡å®Œæˆ!\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ä»»åŠ¡æ€»ç»“:\")\n",
    "print(f\"   Task ID: {task_data_prep.id}\")\n",
    "print(f\"   Taské“¾æ¥: {task_data_prep.get_output_log_web_page()}\")\n",
    "print(f\"   Datasetç‰ˆæœ¬åˆ›å»º:\")\n",
    "print(f\"     - v1.0 (å®Œæ•´æ•°æ®): {dataset_v1.id}\")\n",
    "print(f\"     - v2.0 (è®­ç»ƒ/æµ‹è¯•): {dataset_v2.id}\")\n",
    "print(f\"   é¢„å¤„ç†æ­¥éª¤: {len(preprocessing_steps)} ä¸ª\")\n",
    "print(f\"   æœ€ç»ˆç‰¹å¾æ•°: {X_train.shape[1]}\")\n",
    "\n",
    "# å…³é—­ä»»åŠ¡\n",
    "task_data_prep.close()\n",
    "print(\"\\nâœ… ä»»åŠ¡å·²å…³é—­\")\n",
    "print(\"ğŸ“‹ è¯·è®¿é—®ClearML Webç•Œé¢æŸ¥çœ‹å®Œæ•´ç»“æœ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å®éªŒ 1: DecisionTreeClassifier æ¨¡å‹è®­ç»ƒ\n",
    "åŸºäºä½ çš„åŸæœ‰ä»£ç ï¼Œé›†æˆåˆ° ClearML å®éªŒä¸­\n",
    "\"\"\"\n",
    "\n",
    "# ==================== 1. å¯¼å…¥åº“ ====================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# ==================== 2. è®¾ç½®ClearMLå‡­è¯ ====================\n",
    "# ä½¿ç”¨ä½ å·²æœ‰çš„é…ç½®æ–¹å¼\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=N7LJUE5KY47X5YIOQ0P62YWNM6LMMZ\n",
    "%env CLEARML_API_SECRET_KEY=if0s4bvxfz8Vrlx9vXgd0_INSvzWlQCFcZfJb_N96WcUjbHb3xIOMYjHCWh2zipx6-g\n",
    "\n",
    "# ==================== 3. åˆå§‹åŒ–MLå®éªŒTask ====================\n",
    "from clearml import Task, Dataset\n",
    "\n",
    "print(\"åˆå§‹åŒ–ç¬¬ä¸€ä¸ªMLå®éªŒä»»åŠ¡...\")\n",
    "task_ml1 = Task.init(\n",
    "    project_name='Adult Income - ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ',\n",
    "    task_name='ML Experiment 1 - DecisionTree',\n",
    "    task_type=Task.TaskTypes.training,\n",
    "    tags=['decision-tree', 'gini', 'baseline', 'ĞºÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ']\n",
    ")\n",
    "\n",
    "print(f\"âœ… MLå®éªŒä»»åŠ¡åˆ›å»ºæˆåŠŸ!\")\n",
    "print(f\"ğŸ“‹ Task ID: {task_ml1.id}\")\n",
    "\n",
    "# ==================== 4. åŠ è½½Dataset v2.0 ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤1: åŠ è½½Dataset v2.0 (è®­ç»ƒ/æµ‹è¯•åˆ†å‰²)\")\n",
    "\n",
    "try:\n",
    "    # è·å–Dataset v2.0\n",
    "    dataset = Dataset.get(\n",
    "        dataset_name='adult_income_splits',\n",
    "        dataset_project='Adult Income - ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ',\n",
    "        dataset_version='2.0'\n",
    "    )\n",
    "    \n",
    "    # è·å–æœ¬åœ°å‰¯æœ¬è·¯å¾„\n",
    "    dataset_path = dataset.get_local_copy()\n",
    "    print(f\"âœ… Dataset v2.0 åŠ è½½æˆåŠŸ!\")\n",
    "    print(f\"ğŸ“‚ æœ¬åœ°è·¯å¾„: {dataset_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ DatasetåŠ è½½å¤±è´¥: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿æ•°æ®é¢„å¤„ç†ä»»åŠ¡å·²å®Œæˆå¹¶åˆ›å»ºäº†Dataset v2.0\")\n",
    "    exit()\n",
    "\n",
    "# ==================== 5. åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ® ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤2: åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®\")\n",
    "\n",
    "# åŠ è½½è®­ç»ƒæ•°æ®\n",
    "train_data_file = os.path.join(dataset_path, 'adult_train_data.pkl')\n",
    "with open(train_data_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "X_train = np.array(train_data['X'])\n",
    "y_train = np.array(train_data['y'])\n",
    "\n",
    "# åŠ è½½æµ‹è¯•æ•°æ®\n",
    "test_data_file = os.path.join(dataset_path, 'adult_test_data.pkl')\n",
    "with open(test_data_file, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X_test = np.array(test_data['X'])\n",
    "y_test = np.array(test_data['y'])\n",
    "\n",
    "print(f\"âœ… æ•°æ®åŠ è½½å®Œæˆ:\")\n",
    "print(f\"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾\")\n",
    "print(f\"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬\")\n",
    "\n",
    "# ==================== 6. è®¾ç½®å¹¶è®°å½•è¶…å‚æ•° ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤3: è®¾ç½®å¹¶è®°å½•è¶…å‚æ•°\")\n",
    "\n",
    "# åŸºäºä½ çš„åŸå§‹ä»£ç è®¾ç½®è¶…å‚æ•°\n",
    "hyperparams = {\n",
    "    'model_type': 'DecisionTreeClassifier',\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 5,\n",
    "    'random_state': 100,\n",
    "    'test_size': 0.3,\n",
    "    'dataset_version': '2.0',\n",
    "    'features_used': X_train.shape[1]\n",
    "}\n",
    "\n",
    "# è¿æ¥åˆ°Taské…ç½® (è¿™å°†å‡ºç°åœ¨ClearMLçš„Configurationæ ‡ç­¾é¡µ)\n",
    "task_ml1.connect(hyperparams)\n",
    "print(\"âœ… è¶…å‚æ•°å·²è®°å½•åˆ°ClearML\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ä½¿ç”¨çš„è¶…å‚æ•°:\")\n",
    "for key, value in hyperparams.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# ==================== 7. è®­ç»ƒæ¨¡å‹ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤4: è®­ç»ƒDecisionTreeæ¨¡å‹\")\n",
    "\n",
    "print(\"å¼€å§‹è®­ç»ƒæ¨¡å‹...\")\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion=hyperparams['criterion'],\n",
    "    max_depth=hyperparams['max_depth'],\n",
    "    min_samples_leaf=hyperparams['min_samples_leaf'],\n",
    "    random_state=hyperparams['random_state']\n",
    ")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!\")\n",
    "\n",
    "# è·å–æ¨¡å‹ç‰¹å¾é‡è¦æ€§\n",
    "feature_importance = model.feature_importances_\n",
    "print(f\"\\nğŸ” ç‰¹å¾é‡è¦æ€§ (å‰5ä¸ª):\")\n",
    "for i, imp in enumerate(feature_importance[:5]):\n",
    "    print(f\"   ç‰¹å¾ {i}: {imp:.4f}\")\n",
    "\n",
    "# ==================== 8. æ¨¡å‹è¯„ä¼° ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤5: æ¨¡å‹è¯„ä¼°\")\n",
    "\n",
    "# é¢„æµ‹\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "# è®¡ç®—å…¶ä»–æŒ‡æ ‡\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# è·å–é¢„æµ‹æ¦‚ç‡ï¼ˆç”¨äºAUCè®¡ç®—ï¼‰\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# è®¡ç®—AUC\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba) * 100\n",
    "    print(f\"   AUCåˆ†æ•°: {auc_score:.2f}%\")\n",
    "except Exception as e:\n",
    "    auc_score = None\n",
    "    print(f\"   AUCè®¡ç®—å¤±è´¥: {e}\")\n",
    "precision = precision_score(y_test, y_pred, average='weighted') * 100\n",
    "recall = recall_score(y_test, y_pred, average='weighted') * 100\n",
    "f1 = f1_score(y_test, y_pred, average='weighted') * 100\n",
    "\n",
    "print(f\"ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:\")\n",
    "print(f\"   å‡†ç¡®ç‡ (Accuracy): {accuracy:.2f}%\")\n",
    "print(f\"   ç²¾ç¡®ç‡ (Precision): {precision:.2f}%\")\n",
    "print(f\"   å¬å›ç‡ (Recall): {recall:.2f}%\")\n",
    "print(f\"   F1åˆ†æ•°: {f1:.2f}%\")\n",
    "\n",
    "# ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š\n",
    "print(f\"\\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\")\n",
    "report = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'])\n",
    "print(report)\n",
    "\n",
    "# ==================== 9. è®°å½•æŒ‡æ ‡åˆ°ClearML ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤6: è®°å½•æŒ‡æ ‡åˆ°ClearML\")\n",
    "\n",
    "# è·å–logger\n",
    "logger = task_ml1.get_logger()\n",
    "\n",
    "# è®°å½•å•å€¼æŒ‡æ ‡ (å°†å‡ºç°åœ¨RESULTS â†’ SCALARS)\n",
    "logger.report_single_value(name=\"test_accuracy\", value=accuracy)\n",
    "logger.report_single_value(name=\"test_precision\", value=precision)\n",
    "logger.report_single_value(name=\"test_recall\", value=recall)\n",
    "logger.report_single_value(name=\"test_f1\", value=f1)\n",
    "\n",
    "# è®°å½•AUCåˆ†æ•°ï¼ˆå¦‚æœè®¡ç®—æˆåŠŸï¼‰\n",
    "if auc_score is not None:\n",
    "    logger.report_single_value(name=\"test_auc\", value=auc_score)\n",
    "    print(\"âœ… AUCå·²è®°å½•åˆ°ClearML\")\n",
    "\n",
    "print(\"âœ… æŒ‡æ ‡å·²è®°å½•åˆ°ClearML (RESULTS â†’ SCALARS)\")\n",
    "\n",
    "# è®°å½•åˆ†ç±»æŠ¥å‘Šä½œä¸ºè¡¨æ ¼\n",
    "print(\"\\nè®°å½•åˆ†ç±»æŠ¥å‘Šè¡¨æ ¼...\")\n",
    "report_dict = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'], output_dict=True)\n",
    "\n",
    "# åˆ›å»ºè¡¨æ ¼æ•°æ®\n",
    "table_data = [[\"ç±»åˆ«\", \"ç²¾ç¡®ç‡\", \"å¬å›ç‡\", \"F1åˆ†æ•°\", \"æ”¯æŒåº¦\"]]\n",
    "for class_name in ['<=50K', '>50K']:\n",
    "    metrics = report_dict[class_name]\n",
    "    table_data.append([\n",
    "        class_name,\n",
    "        f\"{metrics['precision']*100:.2f}%\",\n",
    "        f\"{metrics['recall']*100:.2f}%\",\n",
    "        f\"{metrics['f1-score']*100:.2f}%\",\n",
    "        int(metrics['support'])\n",
    "    ])\n",
    "\n",
    "# æ·»åŠ åŠ æƒå¹³å‡\n",
    "metrics = report_dict['weighted avg']\n",
    "table_data.append([\n",
    "    \"åŠ æƒå¹³å‡\",\n",
    "    f\"{metrics['precision']*100:.2f}%\",\n",
    "    f\"{metrics['recall']*100:.2f}%\",\n",
    "    f\"{metrics['f1-score']*100:.2f}%\",\n",
    "    int(report_dict['macro avg']['support'] * 2)  # æ€»æ ·æœ¬æ•°\n",
    "])\n",
    "\n",
    "logger.report_table(\n",
    "    title=\"åˆ†ç±»æŠ¥å‘Šè¯¦æƒ…\",\n",
    "    series=\"decision_tree\",\n",
    "    table_plot=table_data\n",
    ")\n",
    "\n",
    "# ==================== 10. è®°å½•æ··æ·†çŸ©é˜µ ====================\n",
    "print(\"\\nè®°å½•æ··æ·†çŸ©é˜µ...\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# åˆ›å»ºæ··æ·†çŸ©é˜µå¯è§†åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['<=50K', '>50K'],\n",
    "            yticklabels=['<=50K', '>50K'])\n",
    "plt.title('æ··æ·†çŸ©é˜µ - DecisionTree')\n",
    "plt.ylabel('çœŸå®æ ‡ç­¾')\n",
    "plt.xlabel('é¢„æµ‹æ ‡ç­¾')\n",
    "plt.tight_layout()\n",
    "\n",
    "# ä½¿ç”¨report_matplotlib_figureæ–¹æ³•ç›´æ¥æŠ¥å‘Šå›¾å½¢\n",
    "logger.report_matplotlib_figure(\n",
    "    title=\"æ··æ·†çŸ©é˜µ\",\n",
    "    series=\"confusion_matrix\",\n",
    "    figure=plt.gcf(),\n",
    "    report_interactive=False\n",
    ")\n",
    "\n",
    "# ä¿å­˜å›¾åƒæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
    "cm_image_path = 'confusion_matrix.png'\n",
    "plt.savefig(cm_image_path, dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ… æ··æ·†çŸ©é˜µå·²è®°å½•\")\n",
    "\n",
    "# ä¸Šä¼ æ··æ·†çŸ©é˜µå›¾åƒä½œä¸ºArtifact\n",
    "task_ml1.upload_artifact(\n",
    "    name='confusion_matrix.png',\n",
    "    artifact_object=cm_image_path\n",
    ")\n",
    "\n",
    "# åœ¨è®°å½•æ··æ·†çŸ©é˜µçš„éƒ¨åˆ†ä¹‹åï¼Œæ·»åŠ ROCæ›²çº¿\n",
    "print(\"\\nè®°å½•ROCæ›²çº¿...\")\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# è®¡ç®—ROCæ›²çº¿\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# ç»˜åˆ¶ROCæ›²çº¿\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {auc_score:.2f}%)')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='éšæœºçŒœæµ‹')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('å‡æ­£ç‡ (FPR)')\n",
    "plt.ylabel('çœŸæ­£ç‡ (TPR)')\n",
    "plt.title('ROCæ›²çº¿ - DecisionTree')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "\n",
    "# è®°å½•åˆ°ClearML\n",
    "logger.report_matplotlib_figure(\n",
    "    title=\"ROCæ›²çº¿\",\n",
    "    series=\"roc_curve\",\n",
    "    figure=plt.gcf(),\n",
    "    report_interactive=False\n",
    ")\n",
    "\n",
    "# ä¿å­˜å›¾åƒ\n",
    "roc_image_path = 'roc_curve_dt.png'\n",
    "plt.savefig(roc_image_path, dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ… ROCæ›²çº¿å·²è®°å½•\")\n",
    "\n",
    "# ä¸Šä¼ ROCæ›²çº¿å›¾åƒä½œä¸ºArtifact\n",
    "task_ml1.upload_artifact(\n",
    "    name='roc_curve_dt.png',\n",
    "    artifact_object=roc_image_path\n",
    ")\n",
    "\n",
    "# ==================== 11. ä¿å­˜æ¨¡å‹ä¸ºpklæ–‡ä»¶ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤7: ä¿å­˜æ¨¡å‹ä¸ºpklæ–‡ä»¶\")\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "model_filename = 'decision_tree_model_v1.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: {model_filename}\")\n",
    "\n",
    "# ä¿å­˜ç‰¹å¾é‡è¦æ€§\n",
    "feature_importance_dict = {\n",
    "    'feature_importances': feature_importance.tolist(),\n",
    "    'top_features': []\n",
    "}\n",
    "\n",
    "# è¯†åˆ«æœ€é‡è¦çš„ç‰¹å¾\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "for i, idx in enumerate(indices[:10]):  # å‰10ä¸ªæœ€é‡è¦ç‰¹å¾\n",
    "    feature_importance_dict['top_features'].append({\n",
    "        'feature_index': int(idx),\n",
    "        'importance': float(feature_importance[idx])\n",
    "    })\n",
    "\n",
    "importance_filename = 'feature_importance.json'\n",
    "with open(importance_filename, 'w') as f:\n",
    "    json.dump(feature_importance_dict, f, indent=2)\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜ä¸º: {importance_filename}\")\n",
    "\n",
    "# ==================== 12. ä¸Šä¼ æ¨¡å‹å’Œæ–‡ä»¶ä½œä¸ºArtifact ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤8: ä¸Šä¼ æ¨¡å‹å’Œæ–‡ä»¶åˆ°ClearML\")\n",
    "\n",
    "# ä¸Šä¼ æ¨¡å‹\n",
    "task_ml1.upload_artifact(\n",
    "    name='decision_tree_model.pkl',\n",
    "    artifact_object=model_filename,\n",
    "    metadata={\n",
    "        'model_type': 'DecisionTreeClassifier',\n",
    "        'accuracy': accuracy,\n",
    "        'hyperparameters': hyperparams\n",
    "    }\n",
    ")\n",
    "\n",
    "# ä¸Šä¼ ç‰¹å¾é‡è¦æ€§\n",
    "task_ml1.upload_artifact(\n",
    "    name='feature_importance.json',\n",
    "    artifact_object=importance_filename\n",
    ")\n",
    "\n",
    "# ä¸Šä¼ æ··æ·†çŸ©é˜µå›¾åƒ\n",
    "task_ml1.upload_artifact(\n",
    "    name='confusion_matrix.png',\n",
    "    artifact_object=cm_image_path\n",
    ")\n",
    "\n",
    "print(\"âœ… æ¨¡å‹å’Œæ–‡ä»¶å·²ä¸Šä¼ ä¸ºArtifact\")\n",
    "\n",
    "# ==================== 13. è®°å½•å®éªŒæ€»ç»“ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤9: è®°å½•å®éªŒæ€»ç»“\")\n",
    "\n",
    "# åˆ›å»ºå®éªŒæ€»ç»“\n",
    "experiment_summary = {\n",
    "    'experiment_info': {\n",
    "        'task_id': task_ml1.id,\n",
    "        'model': 'DecisionTreeClassifier',\n",
    "        'dataset_version': '2.0',\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    },\n",
    "    'model_info': {\n",
    "        'n_features': X_train.shape[1],\n",
    "        'n_classes': len(np.unique(y_train)),\n",
    "        'tree_depth': model.get_depth(),\n",
    "        'n_leaves': model.get_n_leaves()\n",
    "    },\n",
    "    'hyperparameters_used': hyperparams\n",
    "}\n",
    "\n",
    "# è®°å½•æ€»ç»“è¡¨æ ¼\n",
    "summary_table = [\n",
    "    [\"æŒ‡æ ‡\", \"å€¼\"],\n",
    "    [\"å‡†ç¡®ç‡\", f\"{accuracy:.2f}%\"],\n",
    "    [\"ç²¾ç¡®ç‡\", f\"{precision:.2f}%\"],\n",
    "    [\"å¬å›ç‡\", f\"{recall:.2f}%\"],\n",
    "    [\"F1åˆ†æ•°\", f\"{f1:.2f}%\"],\n",
    "    [\"AUCåˆ†æ•°\", f\"{auc_score:.2f}%\" if auc_score is not None else \"N/A\"],\n",
    "    [\"ç‰¹å¾æ•°é‡\", X_train.shape[1]],\n",
    "    [\"æ ‘æ·±åº¦\", model.get_depth()],\n",
    "    [\"å¶å­èŠ‚ç‚¹æ•°\", model.get_n_leaves()],\n",
    "    [\"æ•°æ®é›†ç‰ˆæœ¬\", \"2.0\"],\n",
    "    [\"æµ‹è¯•é›†å¤§å°\", f\"{X_test.shape[0]} æ ·æœ¬\"]\n",
    "]\n",
    "\n",
    "logger.report_table(\n",
    "    title=\"å®éªŒæ€»ç»“\",\n",
    "    series=\"summary\",\n",
    "    table_plot=summary_table\n",
    ")\n",
    "\n",
    "# ==================== 14. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤10: æ¸…ç†ä¸´æ—¶æ–‡ä»¶\")\n",
    "\n",
    "import os\n",
    "temp_files = [model_filename, importance_filename, cm_image_path]\n",
    "for file in temp_files:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"ğŸ—‘ï¸  å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file}\")\n",
    "\n",
    "# ==================== 15. å®Œæˆä»»åŠ¡ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ ç¬¬ä¸€ä¸ªMLå®éªŒå®Œæˆ!\")\n",
    "\n",
    "print(f\"\\nğŸ“Š å®éªŒæ€»ç»“:\")\n",
    "print(f\"   ä»»åŠ¡ID: {task_ml1.id}\")\n",
    "print(f\"   ä»»åŠ¡é“¾æ¥: {task_ml1.get_output_log_web_page()}\")\n",
    "print(f\"   æ¨¡å‹: DecisionTreeClassifier\")\n",
    "print(f\"   å‡†ç¡®ç‡: {accuracy:.2f}%\")\n",
    "print(f\"   æ•°æ®é›†ç‰ˆæœ¬: 2.0\")\n",
    "print(f\"   è¶…å‚æ•°:\")\n",
    "for key, value in hyperparams.items():\n",
    "    if key not in ['test_size', 'dataset_version', 'features_used']:\n",
    "        print(f\"     {key}: {value}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ åœ¨ClearMLä¸­å¯ä»¥æŸ¥çœ‹:\")\n",
    "print(f\"   - Configuration: è¶…å‚æ•°\")\n",
    "print(f\"   - Artifacts: æ¨¡å‹æ–‡ä»¶ (.pkl)\")\n",
    "print(f\"   - RESULTS â†’ SCALARS: å‡†ç¡®ç‡ç­‰æŒ‡æ ‡\")\n",
    "print(f\"   - RESULTS â†’ PLOTS: æ··æ·†çŸ©é˜µ\")\n",
    "\n",
    "# å…³é—­ä»»åŠ¡\n",
    "task_ml1.close()\n",
    "print(\"\\nâœ… ä»»åŠ¡å·²å…³é—­\")\n",
    "print(\"ğŸ“‹ è¯·è®¿é—®ClearML Webç•Œé¢æŸ¥çœ‹å®Œæ•´ç»“æœ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e149c189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=N7LJUE5KY47X5YIOQ0P62YWNM6LMMZ\n",
      "env: CLEARML_API_SECRET_KEY=if0s4bvxfz8Vrlx9vXgd0_INSvzWlQCFcZfJb_N96WcUjbHb3xIOMYjHCWh2zipx6-g\n",
      "åˆå§‹åŒ–ç¬¬äºŒä¸ªMLå®éªŒä»»åŠ¡...\n",
      "âœ… MLå®éªŒä»»åŠ¡2åˆ›å»ºæˆåŠŸ!\n",
      "ğŸ“‹ Task ID: 24ac78ed937240de89499b9e96513fa7\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤1: åŠ è½½Dataset v2.0 (ä¸å®éªŒ1ç›¸åŒ)\n",
      "âœ… Dataset v2.0 åŠ è½½æˆåŠŸ!\n",
      "ğŸ“‚ æœ¬åœ°è·¯å¾„: C:/Users/User/.clearml/cache/storage_manager/datasets/ds_a49570fdf5eb453498b94ce70baddd3f\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤2: åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®\n",
      "âœ… æ•°æ®åŠ è½½å®Œæˆ:\n",
      "   è®­ç»ƒé›†: 34189 æ ·æœ¬, 12 ç‰¹å¾\n",
      "   æµ‹è¯•é›†: 14653 æ ·æœ¬\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤3: è®¾ç½®å¹¶è®°å½•RandomForestè¶…å‚æ•°\n",
      "âœ… è¶…å‚æ•°å·²è®°å½•åˆ°ClearML\n",
      "\n",
      "ğŸ“‹ ä½¿ç”¨çš„ä¸»è¦è¶…å‚æ•°:\n",
      "   model_type: RandomForestClassifier\n",
      "   n_estimators: 100\n",
      "   criterion: gini\n",
      "   max_depth: 10\n",
      "   min_samples_split: 2\n",
      "   min_samples_leaf: 1\n",
      "   max_features: sqrt\n",
      "   bootstrap: True\n",
      "   oob_score: True\n",
      "   random_state: 42\n",
      "   n_jobs: -1\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤4: è®­ç»ƒRandomForestæ¨¡å‹\n",
      "å¼€å§‹è®­ç»ƒRandomForestæ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!\n",
      "ğŸ“Š OOBåˆ†æ•°: 0.8614\n",
      "\n",
      "ğŸ” ç‰¹å¾é‡è¦æ€§ (å‰10ä¸ª):\n",
      "   ç‰¹å¾ 5: 0.2457\n",
      "   ç‰¹å¾ 8: 0.2370\n",
      "   ç‰¹å¾ 3: 0.1167\n",
      "   ç‰¹å¾ 0: 0.0978\n",
      "   ç‰¹å¾ 2: 0.0809\n",
      "   ç‰¹å¾ 9: 0.0684\n",
      "   ç‰¹å¾ 10: 0.0570\n",
      "   ç‰¹å¾ 4: 0.0537\n",
      "   ç‰¹å¾ 7: 0.0215\n",
      "   ç‰¹å¾ 1: 0.0115\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤5: æ¨¡å‹è¯„ä¼°\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:\n",
      "   å‡†ç¡®ç‡ (Accuracy): 86.07%\n",
      "   ç²¾ç¡®ç‡ (Precision): 85.64%\n",
      "   å¬å›ç‡ (Recall): 86.07%\n",
      "   F1åˆ†æ•°: 85.05%\n",
      "   AUCåˆ†æ•°: 91.23%\n",
      "\n",
      "ğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.87      0.96      0.91     11116\n",
      "        >50K       0.81      0.55      0.65      3537\n",
      "\n",
      "    accuracy                           0.86     14653\n",
      "   macro avg       0.84      0.75      0.78     14653\n",
      "weighted avg       0.86      0.86      0.85     14653\n",
      "\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤6: è®°å½•æŒ‡æ ‡åˆ°ClearML\n",
      "âœ… æŒ‡æ ‡å·²è®°å½•åˆ°ClearML (RESULTS â†’ SCALARS)\n",
      "\n",
      "è®°å½•åˆ†ç±»æŠ¥å‘Šè¡¨æ ¼...\n",
      "\n",
      "è®°å½•æ··æ·†çŸ©é˜µ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 26631 (\\N{CJK UNIFIED IDEOGRAPH-6807}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 31614 (\\N{CJK UNIFIED IDEOGRAPH-7B7E}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 28151 (\\N{CJK UNIFIED IDEOGRAPH-6DF7}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 28102 (\\N{CJK UNIFIED IDEOGRAPH-6DC6}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 30697 (\\N{CJK UNIFIED IDEOGRAPH-77E9}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:255: UserWarning:\n",
      "\n",
      "Glyph 38453 (\\N{CJK UNIFIED IDEOGRAPH-9635}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 26631 (\\N{CJK UNIFIED IDEOGRAPH-6807}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 31614 (\\N{CJK UNIFIED IDEOGRAPH-7B7E}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 28151 (\\N{CJK UNIFIED IDEOGRAPH-6DF7}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 28102 (\\N{CJK UNIFIED IDEOGRAPH-6DC6}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 30697 (\\N{CJK UNIFIED IDEOGRAPH-77E9}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 38453 (\\N{CJK UNIFIED IDEOGRAPH-9635}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 23454 (\\N{CJK UNIFIED IDEOGRAPH-5B9E}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 26631 (\\N{CJK UNIFIED IDEOGRAPH-6807}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 31614 (\\N{CJK UNIFIED IDEOGRAPH-7B7E}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 28151 (\\N{CJK UNIFIED IDEOGRAPH-6DF7}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 28102 (\\N{CJK UNIFIED IDEOGRAPH-6DC6}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 30697 (\\N{CJK UNIFIED IDEOGRAPH-77E9}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 38453 (\\N{CJK UNIFIED IDEOGRAPH-9635}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 39044 (\\N{CJK UNIFIED IDEOGRAPH-9884}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:267: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 20551 (\\N{CJK UNIFIED IDEOGRAPH-5047}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 27491 (\\N{CJK UNIFIED IDEOGRAPH-6B63}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ··æ·†çŸ©é˜µå·²è®°å½•\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤7: è®°å½•ROCæ›²çº¿\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 38543 (\\N{CJK UNIFIED IDEOGRAPH-968F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 26426 (\\N{CJK UNIFIED IDEOGRAPH-673A}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 29468 (\\N{CJK UNIFIED IDEOGRAPH-731C}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:289: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 27491 (\\N{CJK UNIFIED IDEOGRAPH-6B63}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 20551 (\\N{CJK UNIFIED IDEOGRAPH-5047}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 38543 (\\N{CJK UNIFIED IDEOGRAPH-968F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 26426 (\\N{CJK UNIFIED IDEOGRAPH-673A}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 29468 (\\N{CJK UNIFIED IDEOGRAPH-731C}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 27491 (\\N{CJK UNIFIED IDEOGRAPH-6B63}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 20551 (\\N{CJK UNIFIED IDEOGRAPH-5047}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 38543 (\\N{CJK UNIFIED IDEOGRAPH-968F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 26426 (\\N{CJK UNIFIED IDEOGRAPH-673A}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 29468 (\\N{CJK UNIFIED IDEOGRAPH-731C}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 20551 (\\N{CJK UNIFIED IDEOGRAPH-5047}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 27491 (\\N{CJK UNIFIED IDEOGRAPH-6B63}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 38543 (\\N{CJK UNIFIED IDEOGRAPH-968F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 26426 (\\N{CJK UNIFIED IDEOGRAPH-673A}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 29468 (\\N{CJK UNIFIED IDEOGRAPH-731C}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\clearml\\binding\\matplotlib_bind.py:251: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 30495 (\\N{CJK UNIFIED IDEOGRAPH-771F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 27491 (\\N{CJK UNIFIED IDEOGRAPH-6B63}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 29575 (\\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 20551 (\\N{CJK UNIFIED IDEOGRAPH-5047}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 38543 (\\N{CJK UNIFIED IDEOGRAPH-968F}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 26426 (\\N{CJK UNIFIED IDEOGRAPH-673A}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 29468 (\\N{CJK UNIFIED IDEOGRAPH-731C}) missing from font(s) DejaVu Sans.\n",
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20620\\910761404.py:301: UserWarning:\n",
      "\n",
      "Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from font(s) DejaVu Sans.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ROCæ›²çº¿å·²è®°å½• (AUC = 91.23%)\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤8: ä¿å­˜æ¨¡å‹ä¸ºpklæ–‡ä»¶\n",
      "âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: random_forest_model_v1.pkl\n",
      "âœ… ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜ä¸º: feature_importance_rf.json\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤9: ä¸Šä¼ æ¨¡å‹å’Œæ–‡ä»¶åˆ°ClearML\n",
      "âœ… æ¨¡å‹å’Œæ–‡ä»¶å·²ä¸Šä¼ ä¸ºArtifact\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤10: è®°å½•å®éªŒæ€»ç»“\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤11: å®éªŒå¯¹æ¯”æ€»ç»“\n",
      "\n",
      "ğŸ“Š AUCå¯¹æ¯” (å®éªŒ1 vs å®éªŒ2):\n",
      "   å®éªŒ1 (DecisionTree) AUC: 86.73%\n",
      "   å®éªŒ2 (RandomForest) AUC: 91.23%\n",
      "   æ”¹è¿›: 4.50%\n",
      "\n",
      "ğŸ“Š å®éªŒå¯¹æ¯”:\n",
      "   å®éªŒ1 (DecisionTree): 82.58% å‡†ç¡®ç‡\n",
      "   å®éªŒ2 (RandomForest): 86.07% å‡†ç¡®ç‡\n",
      "   å·®å¼‚: 3.49%\n",
      "\n",
      "==================================================\n",
      "æ­¥éª¤12: æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
      "âš ï¸  è­¦å‘Š: æ— æ³•åˆ é™¤ random_forest_model_v1.pklï¼Œæ–‡ä»¶å¯èƒ½è¢«å…¶ä»–ç¨‹åºé”å®š\n",
      "    è¯·ç¨åæ‰‹åŠ¨åˆ é™¤æ­¤æ–‡ä»¶\n",
      "ğŸ—‘ï¸  å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: feature_importance_rf.json\n",
      "ğŸ—‘ï¸  å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: confusion_matrix_rf.png\n",
      "ğŸ—‘ï¸  å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: roc_curve_rf.png\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ ç¬¬äºŒä¸ªMLå®éªŒå®Œæˆ!\n",
      "\n",
      "ğŸ“Š å®éªŒæ€»ç»“:\n",
      "   ä»»åŠ¡ID: 24ac78ed937240de89499b9e96513fa7\n",
      "   ä»»åŠ¡é“¾æ¥: https://app.clear.ml/projects/f515e51c6fa94d259f4175808f6ac5d6/experiments/24ac78ed937240de89499b9e96513fa7/output/log\n",
      "   æ¨¡å‹: RandomForestClassifier\n",
      "   å‡†ç¡®ç‡: 86.07%\n",
      "   æ ‘çš„æ•°é‡: 100\n",
      "   æ•°æ®é›†ç‰ˆæœ¬: 2.0\n",
      "\n",
      "ğŸ“‹ åœ¨ClearMLä¸­å¯ä»¥æŸ¥çœ‹:\n",
      "   - Configuration: RandomForestè¶…å‚æ•°\n",
      "   - Artifacts: æ¨¡å‹æ–‡ä»¶ (.pkl)\n",
      "   - RESULTS â†’ SCALARS: å‡†ç¡®ç‡ç­‰æŒ‡æ ‡\n",
      "   - RESULTS â†’ PLOTS: æ··æ·†çŸ©é˜µ\n",
      "\n",
      "âœ… ä»»åŠ¡å·²å…³é—­\n",
      "ğŸ“‹ è¯·è®¿é—®ClearML Webç•Œé¢æŸ¥çœ‹å®Œæ•´ç»“æœ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping upload, could not find object file 'c:/Users/User/Desktop/æœºå™¨å­¦ä¹ å­¦æœŸä½œä¸š/feature_importance_rf.json'\n",
      "Skipping upload, could not find object file 'c:/Users/User/Desktop/æœºå™¨å­¦ä¹ å­¦æœŸä½œä¸š/confusion_matrix_rf.png'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "å®éªŒ 2: RandomForestClassifier æ¨¡å‹è®­ç»ƒ\n",
    "\"\"\"\n",
    "\n",
    "# ==================== 1. å¯¼å…¥åº“ ====================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==================== 2. è®¾ç½®ClearMLå‡­è¯ ====================\n",
    "# ä½¿ç”¨ä½ å·²æœ‰çš„é…ç½®æ–¹å¼\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=N7LJUE5KY47X5YIOQ0P62YWNM6LMMZ\n",
    "%env CLEARML_API_SECRET_KEY=if0s4bvxfz8Vrlx9vXgd0_INSvzWlQCFcZfJb_N96WcUjbHb3xIOMYjHCWh2zipx6-g\n",
    "\n",
    "# ==================== 3. åˆå§‹åŒ–ç¬¬äºŒä¸ªMLå®éªŒTask ====================\n",
    "from clearml import Task, Dataset\n",
    "\n",
    "print(\"åˆå§‹åŒ–ç¬¬äºŒä¸ªMLå®éªŒä»»åŠ¡...\")\n",
    "task_ml2 = Task.init(\n",
    "    project_name='Adult Income - ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ',\n",
    "    task_name='ML Experiment 2 - RandomForest',\n",
    "    task_type=Task.TaskTypes.training,\n",
    "    tags=['random-forest', 'ensemble', 'comparison', 'ĞºÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ']\n",
    ")\n",
    "\n",
    "print(f\"âœ… MLå®éªŒä»»åŠ¡2åˆ›å»ºæˆåŠŸ!\")\n",
    "print(f\"ğŸ“‹ Task ID: {task_ml2.id}\")\n",
    "\n",
    "# ==================== 4. åŠ è½½Dataset v2.0 ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤1: åŠ è½½Dataset v2.0 (ä¸å®éªŒ1ç›¸åŒ)\")\n",
    "\n",
    "try:\n",
    "    # è·å–Dataset v2.0\n",
    "    dataset = Dataset.get(\n",
    "        dataset_name='adult_income_splits',\n",
    "        dataset_project='Adult Income - ĞšÑƒÑ€ÑĞ¾Ğ²Ğ°Ñ',\n",
    "        dataset_version='2.0'\n",
    "    )\n",
    "    \n",
    "    # è·å–æœ¬åœ°å‰¯æœ¬è·¯å¾„\n",
    "    dataset_path = dataset.get_local_copy()\n",
    "    print(f\"âœ… Dataset v2.0 åŠ è½½æˆåŠŸ!\")\n",
    "    print(f\"ğŸ“‚ æœ¬åœ°è·¯å¾„: {dataset_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ DatasetåŠ è½½å¤±è´¥: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿æ•°æ®é¢„å¤„ç†ä»»åŠ¡å·²å®Œæˆå¹¶åˆ›å»ºäº†Dataset v2.0\")\n",
    "    exit()\n",
    "\n",
    "# ==================== 5. åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ® ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤2: åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®\")\n",
    "\n",
    "# åŠ è½½è®­ç»ƒæ•°æ®\n",
    "train_data_file = os.path.join(dataset_path, 'adult_train_data.pkl')\n",
    "with open(train_data_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "X_train = np.array(train_data['X'])\n",
    "y_train = np.array(train_data['y'])\n",
    "\n",
    "# åŠ è½½æµ‹è¯•æ•°æ®\n",
    "test_data_file = os.path.join(dataset_path, 'adult_test_data.pkl')\n",
    "with open(test_data_file, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X_test = np.array(test_data['X'])\n",
    "y_test = np.array(test_data['y'])\n",
    "\n",
    "print(f\"âœ… æ•°æ®åŠ è½½å®Œæˆ:\")\n",
    "print(f\"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾\")\n",
    "print(f\"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬\")\n",
    "\n",
    "# ==================== 6. è®¾ç½®å¹¶è®°å½•è¶…å‚æ•° ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤3: è®¾ç½®å¹¶è®°å½•RandomForestè¶…å‚æ•°\")\n",
    "\n",
    "# RandomForestä¸DecisionTreeä¸åŒçš„è¶…å‚æ•°\n",
    "hyperparams = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'n_estimators': 100,           # æ ‘çš„æ•°é‡\n",
    "    'criterion': 'gini',           # åˆ†å‰²æ ‡å‡†\n",
    "    'max_depth': 10,               # æ ‘çš„æœ€å¤§æ·±åº¦\n",
    "    'min_samples_split': 2,        # å†…éƒ¨èŠ‚ç‚¹å†åˆ’åˆ†æ‰€éœ€æœ€å°æ ·æœ¬æ•°\n",
    "    'min_samples_leaf': 1,         # å¶å­èŠ‚ç‚¹æœ€å°‘æ ·æœ¬æ•°\n",
    "    'max_features': 'sqrt',        # è€ƒè™‘çš„æœ€å¤§ç‰¹å¾æ•°\n",
    "    'bootstrap': True,             # æœ‰æ”¾å›æŠ½æ ·\n",
    "    'oob_score': True,             # ä½¿ç”¨è¢‹å¤–æ ·æœ¬æ¥è¯„ä¼°æ¨¡å‹\n",
    "    'random_state': 42,            # éšæœºç§å­\n",
    "    'n_jobs': -1,                  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ\n",
    "    'test_size': 0.3,\n",
    "    'dataset_version': '2.0',\n",
    "    'features_used': X_train.shape[1]\n",
    "}\n",
    "\n",
    "# è¿æ¥åˆ°Taské…ç½®\n",
    "task_ml2.connect(hyperparams)\n",
    "print(\"âœ… è¶…å‚æ•°å·²è®°å½•åˆ°ClearML\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ä½¿ç”¨çš„ä¸»è¦è¶…å‚æ•°:\")\n",
    "for key, value in hyperparams.items():\n",
    "    if key not in ['test_size', 'dataset_version', 'features_used']:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "# ==================== 7. è®­ç»ƒæ¨¡å‹ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤4: è®­ç»ƒRandomForestæ¨¡å‹\")\n",
    "\n",
    "print(\"å¼€å§‹è®­ç»ƒRandomForestæ¨¡å‹...\")\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=hyperparams['n_estimators'],\n",
    "    criterion=hyperparams['criterion'],\n",
    "    max_depth=hyperparams['max_depth'],\n",
    "    min_samples_split=hyperparams['min_samples_split'],\n",
    "    min_samples_leaf=hyperparams['min_samples_leaf'],\n",
    "    max_features=hyperparams['max_features'],\n",
    "    bootstrap=hyperparams['bootstrap'],\n",
    "    oob_score=hyperparams['oob_score'],\n",
    "    random_state=hyperparams['random_state'],\n",
    "    n_jobs=hyperparams['n_jobs'],\n",
    "    verbose=1  # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦\n",
    ")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!\")\n",
    "\n",
    "# è·å–OOBåˆ†æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "if hasattr(model, 'oob_score_'):\n",
    "    print(f\"ğŸ“Š OOBåˆ†æ•°: {model.oob_score_:.4f}\")\n",
    "\n",
    "# è·å–æ¨¡å‹ç‰¹å¾é‡è¦æ€§\n",
    "feature_importance = model.feature_importances_\n",
    "print(f\"\\nğŸ” ç‰¹å¾é‡è¦æ€§ (å‰10ä¸ª):\")\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "for i, idx in enumerate(indices[:10]):\n",
    "    print(f\"   ç‰¹å¾ {idx}: {feature_importance[idx]:.4f}\")\n",
    "\n",
    "# ==================== 8. æ¨¡å‹è¯„ä¼° ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤5: æ¨¡å‹è¯„ä¼°\")\n",
    "\n",
    "# é¢„æµ‹\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # é¢„æµ‹æ¦‚ç‡ï¼ˆç”¨äºAUCï¼‰\n",
    "# è®¡ç®—ROCæ›²çº¿\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr) * 100\n",
    "# è®¡ç®—å‡†ç¡®ç‡\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "# è®¡ç®—å…¶ä»–æŒ‡æ ‡\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted') * 100\n",
    "recall = recall_score(y_test, y_pred, average='weighted') * 100\n",
    "f1 = f1_score(y_test, y_pred, average='weighted') * 100\n",
    "\n",
    "# è®¡ç®—AUCï¼ˆå¦‚æœé€‚ç”¨ï¼‰\n",
    "try:\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba) * 100\n",
    "except:\n",
    "    auc_score = None\n",
    "\n",
    "print(f\"ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:\")\n",
    "print(f\"   å‡†ç¡®ç‡ (Accuracy): {accuracy:.2f}%\")\n",
    "print(f\"   ç²¾ç¡®ç‡ (Precision): {precision:.2f}%\")\n",
    "print(f\"   å¬å›ç‡ (Recall): {recall:.2f}%\")\n",
    "print(f\"   F1åˆ†æ•°: {f1:.2f}%\")\n",
    "if auc_score:\n",
    "    print(f\"   AUCåˆ†æ•°: {auc_score:.2f}%\")\n",
    "\n",
    "# ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š\n",
    "print(f\"\\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:\")\n",
    "report = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'])\n",
    "print(report)\n",
    "\n",
    "# ==================== 9. è®°å½•æŒ‡æ ‡åˆ°ClearML ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤6: è®°å½•æŒ‡æ ‡åˆ°ClearML\")\n",
    "\n",
    "# è·å–logger\n",
    "logger = task_ml2.get_logger()\n",
    "\n",
    "# è®°å½•å•å€¼æŒ‡æ ‡ (å°†å‡ºç°åœ¨RESULTS â†’ SCALARS)\n",
    "logger.report_single_value(name=\"test_accuracy\", value=accuracy)\n",
    "logger.report_single_value(name=\"test_precision\", value=precision)\n",
    "logger.report_single_value(name=\"test_recall\", value=recall)\n",
    "logger.report_single_value(name=\"test_f1\", value=f1)\n",
    "\n",
    "if auc_score:\n",
    "    logger.report_single_value(name=\"test_auc\", value=auc_score)\n",
    "\n",
    "# è®°å½•OOBåˆ†æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "if hasattr(model, 'oob_score_'):\n",
    "    logger.report_single_value(name=\"oob_score\", value=model.oob_score_ * 100)\n",
    "\n",
    "print(\"âœ… æŒ‡æ ‡å·²è®°å½•åˆ°ClearML (RESULTS â†’ SCALARS)\")\n",
    "\n",
    "# è®°å½•åˆ†ç±»æŠ¥å‘Šä½œä¸ºè¡¨æ ¼\n",
    "print(\"\\nè®°å½•åˆ†ç±»æŠ¥å‘Šè¡¨æ ¼...\")\n",
    "report_dict = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'], output_dict=True)\n",
    "\n",
    "# åˆ›å»ºè¡¨æ ¼æ•°æ®\n",
    "table_data = [[\"ç±»åˆ«\", \"ç²¾ç¡®ç‡\", \"å¬å›ç‡\", \"F1åˆ†æ•°\", \"æ”¯æŒåº¦\"]]\n",
    "for class_name in ['<=50K', '>50K']:\n",
    "    metrics = report_dict[class_name]\n",
    "    table_data.append([\n",
    "        class_name,\n",
    "        f\"{metrics['precision']*100:.2f}%\",\n",
    "        f\"{metrics['recall']*100:.2f}%\",\n",
    "        f\"{metrics['f1-score']*100:.2f}%\",\n",
    "        int(metrics['support'])\n",
    "    ])\n",
    "\n",
    "# æ·»åŠ åŠ æƒå¹³å‡\n",
    "metrics = report_dict['weighted avg']\n",
    "table_data.append([\n",
    "    \"åŠ æƒå¹³å‡\",\n",
    "    f\"{metrics['precision']*100:.2f}%\",\n",
    "    f\"{metrics['recall']*100:.2f}%\",\n",
    "    f\"{metrics['f1-score']*100:.2f}%\",\n",
    "    int(report_dict['macro avg']['support'] * 2)\n",
    "])\n",
    "\n",
    "logger.report_table(\n",
    "    title=\"åˆ†ç±»æŠ¥å‘Šè¯¦æƒ…\",\n",
    "    series=\"random_forest\",\n",
    "    table_plot=table_data\n",
    ")\n",
    "\n",
    "# ==================== 10. è®°å½•æ··æ·†çŸ©é˜µ ====================\n",
    "print(\"\\nè®°å½•æ··æ·†çŸ©é˜µ...\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# åˆ›å»ºæ··æ·†çŸ©é˜µå¯è§†åŒ–\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['<=50K', '>50K'],\n",
    "            yticklabels=['<=50K', '>50K'])\n",
    "plt.title('æ··æ·†çŸ©é˜µ - RandomForest')\n",
    "plt.ylabel('çœŸå®æ ‡ç­¾')\n",
    "plt.xlabel('é¢„æµ‹æ ‡ç­¾')\n",
    "plt.tight_layout()\n",
    "\n",
    "# ä½¿ç”¨report_matplotlib_figureæ–¹æ³•ç›´æ¥æŠ¥å‘Šå›¾å½¢\n",
    "logger.report_matplotlib_figure(\n",
    "    title=\"æ··æ·†çŸ©é˜µ\",\n",
    "    series=\"confusion_matrix\",\n",
    "    figure=plt.gcf(),\n",
    "    report_interactive=False\n",
    ")\n",
    "\n",
    "# ä¿å­˜å›¾åƒæ–‡ä»¶\n",
    "cm_image_path = 'confusion_matrix_rf.png'\n",
    "plt.savefig(cm_image_path, dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ… æ··æ·†çŸ©é˜µå·²è®°å½•\")\n",
    "\n",
    "# ==================== 11. è®°å½•ROCæ›²çº¿ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤7: è®°å½•ROCæ›²çº¿\")\n",
    "\n",
    "# ç»˜åˆ¶ROCæ›²çº¿\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROCæ›²çº¿ (AUC = {roc_auc:.2f}%)')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='éšæœºçŒœæµ‹')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('å‡æ­£ç‡ (False Positive Rate)')\n",
    "plt.ylabel('çœŸæ­£ç‡ (True Positive Rate)')\n",
    "plt.title('ROCæ›²çº¿ - RandomForest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# è®°å½•åˆ°ClearML\n",
    "logger.report_matplotlib_figure(\n",
    "    title=\"ROCæ›²çº¿\",\n",
    "    series=\"roc_curve\",\n",
    "    figure=plt.gcf(),\n",
    "    report_interactive=False\n",
    ")\n",
    "\n",
    "# ä¿å­˜å›¾åƒ\n",
    "roc_image_path = 'roc_curve_rf.png'\n",
    "plt.savefig(roc_image_path, dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"âœ… ROCæ›²çº¿å·²è®°å½• (AUC = {roc_auc:.2f}%)\")\n",
    "\n",
    "# ä¸Šä¼ ROCæ›²çº¿å›¾åƒä½œä¸ºArtifact\n",
    "task_ml2.upload_artifact(\n",
    "    name='roc_curve_rf.png',\n",
    "    artifact_object=roc_image_path\n",
    ")\n",
    "# ==================== 12. ä¿å­˜æ¨¡å‹ä¸ºpklæ–‡ä»¶ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤8: ä¿å­˜æ¨¡å‹ä¸ºpklæ–‡ä»¶\")\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "model_filename = 'random_forest_model_v1.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: {model_filename}\")\n",
    "\n",
    "# ä¿å­˜ç‰¹å¾é‡è¦æ€§\n",
    "feature_importance_dict = {\n",
    "    'feature_importances': feature_importance.tolist(),\n",
    "    'top_features': []\n",
    "}\n",
    "\n",
    "# è¯†åˆ«æœ€é‡è¦çš„ç‰¹å¾\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "for i, idx in enumerate(indices[:10]):  # å‰10ä¸ªæœ€é‡è¦ç‰¹å¾\n",
    "    feature_importance_dict['top_features'].append({\n",
    "        'feature_index': int(idx),\n",
    "        'importance': float(feature_importance[idx]),\n",
    "        'rank': i + 1\n",
    "    })\n",
    "\n",
    "importance_filename = 'feature_importance_rf.json'\n",
    "with open(importance_filename, 'w') as f:\n",
    "    json.dump(feature_importance_dict, f, indent=2)\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜ä¸º: {importance_filename}\")\n",
    "\n",
    "# ==================== 12. ä¸Šä¼ æ¨¡å‹å’Œæ–‡ä»¶ä½œä¸ºArtifact ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤9: ä¸Šä¼ æ¨¡å‹å’Œæ–‡ä»¶åˆ°ClearML\")\n",
    "\n",
    "# ä¸Šä¼ æ¨¡å‹\n",
    "task_ml2.upload_artifact(\n",
    "    name='random_forest_model.pkl',\n",
    "    artifact_object=model_filename,\n",
    "    metadata={\n",
    "        'model_type': 'RandomForestClassifier',\n",
    "        'accuracy': accuracy,\n",
    "        'hyperparameters': hyperparams\n",
    "    }\n",
    ")\n",
    "\n",
    "# ä¸Šä¼ ç‰¹å¾é‡è¦æ€§\n",
    "task_ml2.upload_artifact(\n",
    "    name='feature_importance_rf.json',\n",
    "    artifact_object=importance_filename\n",
    ")\n",
    "\n",
    "# ä¸Šä¼ æ··æ·†çŸ©é˜µå›¾åƒ\n",
    "task_ml2.upload_artifact(\n",
    "    name='confusion_matrix_rf.png',\n",
    "    artifact_object=cm_image_path\n",
    ")\n",
    "\n",
    "print(\"âœ… æ¨¡å‹å’Œæ–‡ä»¶å·²ä¸Šä¼ ä¸ºArtifact\")\n",
    "\n",
    "# ==================== 13. è®°å½•å®éªŒæ€»ç»“ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤10: è®°å½•å®éªŒæ€»ç»“\")\n",
    "\n",
    "# åˆ›å»ºå®éªŒæ€»ç»“\n",
    "experiment_summary = {\n",
    "    'experiment_info': {\n",
    "        'task_id': task_ml2.id,\n",
    "        'model': 'RandomForestClassifier',\n",
    "        'dataset_version': '2.0',\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    },\n",
    "    'model_info': {\n",
    "        'n_estimators': model.n_estimators,\n",
    "        'n_features': X_train.shape[1],\n",
    "        'n_classes': len(np.unique(y_train)),\n",
    "        'feature_importance_top_3': [\n",
    "            (int(indices[0]), float(feature_importance[indices[0]])),\n",
    "            (int(indices[1]), float(feature_importance[indices[1]])),\n",
    "            (int(indices[2]), float(feature_importance[indices[2]]))\n",
    "        ]\n",
    "    },\n",
    "    'hyperparameters_used': hyperparams\n",
    "}\n",
    "\n",
    "# è®°å½•æ€»ç»“è¡¨æ ¼\n",
    "summary_table = [\n",
    "    [\"æŒ‡æ ‡\", \"å€¼\"],\n",
    "    [\"å‡†ç¡®ç‡\", f\"{accuracy:.2f}%\"],\n",
    "    [\"ç²¾ç¡®ç‡\", f\"{precision:.2f}%\"],\n",
    "    [\"å¬å›ç‡\", f\"{recall:.2f}%\"],\n",
    "    [\"F1åˆ†æ•°\", f\"{f1:.2f}%\"],\n",
    "    [\"æ ‘çš„æ•°é‡\", model.n_estimators],\n",
    "    [\"ç‰¹å¾æ•°é‡\", X_train.shape[1]],\n",
    "    [\"æœ€å¤§æ·±åº¦\", hyperparams['max_depth']],\n",
    "    [\"OOBåˆ†æ•°\", f\"{model.oob_score_:.4f}\" if hasattr(model, 'oob_score_') else \"N/A\"],\n",
    "    [\"æ•°æ®é›†ç‰ˆæœ¬\", \"2.0\"]\n",
    "]\n",
    "\n",
    "logger.report_table(\n",
    "    title=\"å®éªŒæ€»ç»“\",\n",
    "    series=\"summary\",\n",
    "    table_plot=summary_table\n",
    ")\n",
    "\n",
    "# ==================== 14. æ¯”è¾ƒä¸¤ä¸ªå®éªŒçš„æŒ‡æ ‡ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤11: å®éªŒå¯¹æ¯”æ€»ç»“\")\n",
    "\n",
    "print(f\"\\nğŸ“Š AUCå¯¹æ¯” (å®éªŒ1 vs å®éªŒ2):\")\n",
    "exp1_auc = 86.73  \n",
    "print(f\"   å®éªŒ1 (DecisionTree) AUC: {exp1_auc:.2f}%\")\n",
    "print(f\"   å®éªŒ2 (RandomForest) AUC: {roc_auc:.2f}%\")\n",
    "print(f\"   æ”¹è¿›: {roc_auc - exp1_auc:.2f}%\")\n",
    "\n",
    "exp1_accuracy = 82.58  # å®éªŒ1çš„å‡†ç¡®ç‡\n",
    "\n",
    "comparison_table = [\n",
    "    [\"å®éªŒ\", \"æ¨¡å‹\", \"å‡†ç¡®ç‡\",\"AUC\", \"ç²¾ç¡®ç‡\", \"å¬å›ç‡\", \"F1åˆ†æ•°\", \"ç‰¹å¾æ•°\", \"å¤‡æ³¨\"],\n",
    "    [\"å®éªŒ1\", \"DecisionTree\", f\"{exp1_accuracy:.2f}%\", f\"{exp1_auc:.2f}%\",\"~82%\", \"~82%\", \"~82%\", \"12\", \"åŸºå‡†æ¨¡å‹\"],\n",
    "    [\"å®éªŒ2\", \"RandomForest\", f\"{accuracy:.2f}%\", f\"{roc_auc:.2f}%\",f\"{precision:.2f}%\", f\"{recall:.2f}%\", f\"{f1:.2f}%\", \"12\", \"é›†æˆå­¦ä¹ \"]\n",
    "]\n",
    "\n",
    "logger.report_table(\n",
    "    title=\"å®éªŒå¯¹æ¯” (åŒ…å«AUC)\",\n",
    "    series=\"comparison_with_auc\",\n",
    "    table_plot=comparison_table\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š å®éªŒå¯¹æ¯”:\")\n",
    "print(f\"   å®éªŒ1 (DecisionTree): {exp1_accuracy:.2f}% å‡†ç¡®ç‡\")\n",
    "print(f\"   å®éªŒ2 (RandomForest): {accuracy:.2f}% å‡†ç¡®ç‡\")\n",
    "print(f\"   å·®å¼‚: {accuracy - exp1_accuracy:.2f}%\")\n",
    "\n",
    "# ==================== 15. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ­¥éª¤12: æ¸…ç†ä¸´æ—¶æ–‡ä»¶\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "temp_files = [model_filename, importance_filename, cm_image_path, roc_image_path]\n",
    "for file in temp_files:\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"ğŸ—‘ï¸  å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file}\")\n",
    "        except PermissionError:\n",
    "            print(f\"âš ï¸  è­¦å‘Š: æ— æ³•åˆ é™¤ {file}ï¼Œæ–‡ä»¶å¯èƒ½è¢«å…¶ä»–ç¨‹åºé”å®š\")\n",
    "            print(f\"    è¯·ç¨åæ‰‹åŠ¨åˆ é™¤æ­¤æ–‡ä»¶\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  è­¦å‘Š: åˆ é™¤ {file} æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "# ==================== 16. å®Œæˆä»»åŠ¡ ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ‰ ç¬¬äºŒä¸ªMLå®éªŒå®Œæˆ!\")\n",
    "\n",
    "print(f\"\\nğŸ“Š å®éªŒæ€»ç»“:\")\n",
    "print(f\"   ä»»åŠ¡ID: {task_ml2.id}\")\n",
    "print(f\"   ä»»åŠ¡é“¾æ¥: {task_ml2.get_output_log_web_page()}\")\n",
    "print(f\"   æ¨¡å‹: RandomForestClassifier\")\n",
    "print(f\"   å‡†ç¡®ç‡: {accuracy:.2f}%\")\n",
    "print(f\"   æ ‘çš„æ•°é‡: {model.n_estimators}\")\n",
    "print(f\"   æ•°æ®é›†ç‰ˆæœ¬: 2.0\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ åœ¨ClearMLä¸­å¯ä»¥æŸ¥çœ‹:\")\n",
    "print(f\"   - Configuration: RandomForestè¶…å‚æ•°\")\n",
    "print(f\"   - Artifacts: æ¨¡å‹æ–‡ä»¶ (.pkl)\")\n",
    "print(f\"   - RESULTS â†’ SCALARS: å‡†ç¡®ç‡ç­‰æŒ‡æ ‡\")\n",
    "print(f\"   - RESULTS â†’ PLOTS: æ··æ·†çŸ©é˜µ\")\n",
    "\n",
    "# å…³é—­ä»»åŠ¡\n",
    "task_ml2.close()\n",
    "print(\"\\nâœ… ä»»åŠ¡å·²å…³é—­\")\n",
    "print(\"ğŸ“‹ è¯·è®¿é—®ClearML Webç•Œé¢æŸ¥çœ‹å®Œæ•´ç»“æœ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
